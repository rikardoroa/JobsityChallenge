{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1c56fd-86fe-4da5-bae2-08edaf8d234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobsity Test DaG Code For automated Transformation, Download and ingestion in Google Clod DataBase aproach\n",
    "#Ricardo Roa\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import re \n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import Table, Column, Integer, String, MetaData, ForeignKey, Float\n",
    "from twilio.rest import Client\n",
    "from twilio.base.exceptions import TwilioRestException\n",
    "from sqlalchemy.exc import OperationalError\n",
    "from airflow.models import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from datetime import datetime\n",
    "from airflow.providers.http.sensors.http import HttpSensor\n",
    "from urllib.request import Request, urlopen  \n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "default_args = {\n",
    "  'start_date': datetime.today().strftime('%Y-%m-%d')\n",
    "}\n",
    "\n",
    "def process_data():\n",
    "    #Downloading de CSV from Google Drive Link\n",
    "    try:\n",
    "        url='https://drive.google.com/file/d/14JcOSJAWqKOUNyadVZDPm7FplA7XYhrU/view'\n",
    "        path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
    "        req = Request(path)\n",
    "        req.add_header('User-Agent', 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:77.0) Gecko/20100101 Firefox/77.0')\n",
    "        content = urlopen(req)\n",
    "        df = pd.read_csv(content)\n",
    "        df = df.to_dict()\n",
    "        return df\n",
    "    except (NameError,TypeError,UnboundLocalError,ValueError) as error:\n",
    "        print('Declare la variable correcta:',error) \n",
    "        raise\n",
    "        \n",
    "def transform_data():\n",
    "        #Transforming the Dataframe\n",
    "\n",
    "        try:\n",
    "            df2 = pd.DataFrame()\n",
    "            df = process_data()\n",
    "            df = pd.DataFrame.from_dict(df)\n",
    "\n",
    "            #removing noise data for gropping\n",
    "            col = ['origin_coord','destination_coord']\n",
    "            keywords = [\"POINT\",\"(\",\")\",\" \"]\n",
    "            float_point = [\".\"]\n",
    "            for i in range(len(keywords)):\n",
    "                df = df[['origin_coord','destination_coord']].apply(lambda x: x.str.replace(keywords[i],'',regex=True))\n",
    "            for i in range(len(float_point)):\n",
    "                df = df[['origin_coord','destination_coord']].apply(lambda x: x.str.replace(float_point[i],',',regex=True))\n",
    "            df2 = df\n",
    "            df2[['origin_coord','destination_coord']].astype(str)\n",
    "\n",
    "            #reagruping the data  by index\n",
    "            aux_indexes=[]\n",
    "            aux_indexes_=[]\n",
    "            for item, item_ in zip(df2.origin_coord,df2.destination_coord):\n",
    "                index = item.find(\",\")\n",
    "                index_ = item_.find(\",\")\n",
    "                aux_indexes.append(index)\n",
    "                aux_indexes_.append(index_)\n",
    "\n",
    "            df2 = df2[['origin_coord','destination_coord']].apply(lambda x: x.str.replace(',','',regex=True))\n",
    "\n",
    "\n",
    "            new_index_=[]\n",
    "            new_index__=[]\n",
    "\n",
    "            #creating de float values in in origin and destination coordinates\n",
    "            for index, item in zip(aux_indexes,df2.origin_coord):\n",
    "                item = item[:index] + ',' + item[index:]\n",
    "                new_index_.append(item)\n",
    "                new_index_=list(dict.fromkeys(new_index_))\n",
    "\n",
    "\n",
    "            for index, item in zip(aux_indexes_,df2.destination_coord):\n",
    "                item = item[:index] + ',' + item[index:]\n",
    "                new_index__.append(item)\n",
    "                new_index__= list(dict.fromkeys(new_index__))\n",
    "\n",
    "            #creating the new dataframes with the clean data\n",
    "            df4 = pd.DataFrame(new_index_).rename(columns={0:'origin_coord'})\n",
    "            df5 = pd.DataFrame(new_index__).rename(columns={0:'destination_coord'})\n",
    "\n",
    "            df['origin_coord'] = df4[['origin_coord']]\n",
    "            df['destination_coord'] = df5[['destination_coord']]\n",
    "            df = df[['origin_coord','destination_coord']].apply(lambda x: x.str.replace(\",\",\".\",regex=True)).astype(float)\n",
    "            df = df[['origin_coord','destination_coord']].apply(lambda x: x.round(1))\n",
    "            df2 = df\n",
    "            df2 = df2.to_dict()\n",
    "            return df2\n",
    "        except (NameError,TypeError,UnboundLocalError,ValueError) as error:\n",
    "            print('Declare la variable correcta:',error) \n",
    "            raise\n",
    "            \n",
    "def update_data():\n",
    "        try:\n",
    "            #agroping operations\n",
    "            df2 = transform_data()\n",
    "            df2 = pd.DataFrame.from_dict(df2)\n",
    "            df =  process_data()\n",
    "            df = pd.DataFrame.from_dict(df)\n",
    "\n",
    "            df['origin_coord']= df2[['origin_coord']]\n",
    "            df['destination_coord']= df2[['destination_coord']]\n",
    "            df['date'] = pd.to_datetime(df['datetime']).dt.date\n",
    "\n",
    "            df['day'] = df['date'].apply(lambda x : x.day)\n",
    "            df['Hour'] = pd.to_datetime(df['datetime']).dt.hour\n",
    "            df['week'] = df['day'].apply(lambda x: (x-1)//7+1) \n",
    "            \n",
    "            #groping operation\n",
    "            df2 = df.groupby(['region','origin_coord','destination_coord','datetime'])['region'].agg(['count'], ascending=True).\\\n",
    "                rename(columns={'count':'Total'}).reset_index()\n",
    "            df2 = df.groupby(['region'])['week'].agg(['mean'], ascending=True).\\\n",
    "                rename(columns={'mean':'weekly_avg'}).reset_index()\n",
    "        \n",
    "\n",
    "            df3 = pd.merge(left=df,right=df2,how=\"inner\", on=[\"region\"])\n",
    "\n",
    "            df4 = df3.groupby(['region','origin_coord','destination_coord','Hour','weekly_avg'])['weekly_avg'].\\\n",
    "            agg(['count'],ascending=True).rename(columns={'count':'Total'}).reset_index()\n",
    "            df4 = df4.drop(['Total'], axis=1)\n",
    "            \n",
    "            df4 = df4.to_dict()\n",
    "            return df4\n",
    "        except (NameError,TypeError,UnboundLocalError,ValueError) as error:\n",
    "            print('Declare la variable correcta:',error) \n",
    "            raise\n",
    "            \n",
    "def import_data():\n",
    "        try:\n",
    "            \n",
    "            #se carga el df final y la conexion a la bd configurada en gcloud\n",
    "            df = update_data()\n",
    "            df = pd.DataFrame.from_dict(df)\n",
    "            conn_string = 'postgresql://test:test@34.72.31.189:5432/test'\n",
    "            engine = create_engine(conn_string, echo=True)\n",
    "            engine.connect()\n",
    "\n",
    "            #se crea la tabla\n",
    "            meta = MetaData()\n",
    "            trips_data = Table(\n",
    "             'trips_data', meta, \n",
    "               Column('region', String(60)), \n",
    "               Column('origin_coord', Float), \n",
    "               Column('destination_coord', Float),\n",
    "               Column('Hour', Integer), \n",
    "               Column('weekly_avg', Float),\n",
    "              \n",
    "            )\n",
    "            meta.create_all(engine)\n",
    "\n",
    "            #se insertan los datos en la tabla creada\n",
    "            df.to_sql(name ='trips_data', con=engine, index=False, chunksize=500,if_exists='replace')\n",
    "           \n",
    "            account_sid = \"ACa045c88bd06ec82f87f4772f1d864043\"\n",
    "            auth_token  = \"7c82696275a674d4669865a13bb4157a\"\n",
    "            client = Client(account_sid,auth_token)\n",
    "            from_whatsapp_number='whatsapp:+14155238886'\n",
    "            to_whatsapp_number='whatsapp:+573013919941'\n",
    "            client.messages.create(body='Data Inserted',from_=from_whatsapp_number,to=to_whatsapp_number)\n",
    "        except (NameError,TypeError,UnboundLocalError,ValueError,TwilioRestException,AttributeError,OperationalError) as error:\n",
    "            account_sid = \"ACa045c88bd06ec82f87f4772f1d864043\"\n",
    "            auth_token  = \"7c82696275a674d4669865a13bb4157a\"\n",
    "            client = Client(account_sid,auth_token)\n",
    "            from_whatsapp_number='whatsapp:+14155238886'\n",
    "            to_whatsapp_number='whatsapp:+573013919941'\n",
    "            client.messages.create(body='Data not Inserted',from_=from_whatsapp_number,to=to_whatsapp_number)\n",
    "            raise\n",
    "\n",
    "\n",
    "with DAG ('cloud_ingesting', schedule_interval='@daily',dagrun_timeout=timedelta(minutes=1),\n",
    "                default_args = default_args , catchup=False) as dag:\n",
    "\n",
    "    processing_data = PythonOperator(\n",
    "    task_id='processing_data',\n",
    "    python_callable=process_data,\n",
    "    do_xcom_push=True\n",
    "    )\n",
    "\n",
    "    transforming_data = PythonOperator(\n",
    "    task_id='transform_data',\n",
    "    python_callable=transform_data\n",
    "    )\n",
    "\n",
    "    updating_data = PythonOperator(\n",
    "    task_id='update_data',\n",
    "    python_callable=update_data\n",
    "    )\n",
    "\n",
    "    importing_data = PythonOperator(\n",
    "    task_id='import_data',\n",
    "    python_callable=import_data\n",
    "    )\n",
    "    processing_data >> transforming_data >> updating_data >> importing_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
