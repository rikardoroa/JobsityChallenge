{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79816bff-b547-4ce1-a379-b001cab2b170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobsity Test OOP aproach\n",
    "#Ricardo Roa\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import re \n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import Table, Column, Integer, String, MetaData, ForeignKey, Float\n",
    "from twilio.rest import Client\n",
    "from twilio.base.exceptions import TwilioRestException\n",
    "from sqlalchemy.exc import OperationalError\n",
    "import os\n",
    "\n",
    "\n",
    "class ingest_data():\n",
    "    #inicializo variables\n",
    "    def __init__(self, df=pd.DataFrame(),df2=pd.DataFrame()):\n",
    "        self.df = df\n",
    "        self.df2= df2\n",
    "\n",
    "    def process_data(self):\n",
    "        #descarga de csv\n",
    "        try:\n",
    "            url='https://drive.google.com/file/d/14JcOSJAWqKOUNyadVZDPm7FplA7XYhrU/view'\n",
    "            file_id=url.split('/')[-2]\n",
    "            download_data='https://drive.google.com/uc?id=' + file_id\n",
    "            df = pd.read_csv(download_data)\n",
    "            self.df = df\n",
    "            return df\n",
    "        except (NameError,TypeError,UnboundLocalError,ValueError) as error:\n",
    "            print('Declare la variable correcta:',error) \n",
    "            raise\n",
    "        \n",
    "    def transform_data(self):\n",
    "        #transformacion del df\n",
    "        try:\n",
    "            df = self.df\n",
    "            col = ['origin_coord','destination_coord']\n",
    "            keywords = [\"POINT\",\"(\",\")\",\" \"]\n",
    "            float_point = [\".\"]\n",
    "            for i in range(len(keywords)):\n",
    "                df = df[['origin_coord','destination_coord']].apply(lambda x: x.str.replace(keywords[i],'',regex=True))\n",
    "            for i in range(len(float_point)):\n",
    "                df = df[['origin_coord','destination_coord']].apply(lambda x: x.str.replace(float_point[i],',',regex=True))\n",
    "            self.df2 = df\n",
    "            self.df2[['origin_coord','destination_coord']].astype(str)\n",
    "\n",
    "            aux_indexes=[]\n",
    "            aux_indexes_=[]\n",
    "            for item, item_ in zip(self.df2.origin_coord,self.df2.destination_coord):\n",
    "                index = item.find(\",\")\n",
    "                index_ = item_.find(\",\")\n",
    "                aux_indexes.append(index)\n",
    "                aux_indexes_.append(index_)\n",
    "\n",
    "            self.df2 = self.df2[['origin_coord','destination_coord']].apply(lambda x: x.str.replace(',','',regex=True))\n",
    "\n",
    "\n",
    "            new_index_=[]\n",
    "            new_index__=[]\n",
    "\n",
    "\n",
    "            for index, item in zip(aux_indexes,self.df2.origin_coord):\n",
    "                item = item[:index] + ',' + item[index:]\n",
    "                new_index_.append(item)\n",
    "                new_index_=list(dict.fromkeys(new_index_))\n",
    "\n",
    "\n",
    "            for index, item in zip(aux_indexes_,self.df2.destination_coord):\n",
    "                item = item[:index] + ',' + item[index:]\n",
    "                new_index__.append(item)\n",
    "                new_index__= list(dict.fromkeys(new_index__))\n",
    "\n",
    "            df4 = pd.DataFrame(new_index_).rename(columns={0:'origin_coord'})\n",
    "            df5 = pd.DataFrame(new_index__).rename(columns={0:'destination_coord'})\n",
    "\n",
    "            df['origin_coord'] = df4[['origin_coord']]\n",
    "            df['destination_coord'] = df5[['destination_coord']]\n",
    "            df = df[['origin_coord','destination_coord']].apply(lambda x: x.str.replace(\",\",\".\",regex=True)).astype(float)\n",
    "            df = df[['origin_coord','destination_coord']].apply(lambda x: x.round(1))\n",
    "            self.df2 = df\n",
    "            return self.df2\n",
    "        except (NameError,TypeError,UnboundLocalError,ValueError) as error:\n",
    "            print('Declare la variable correcta:',error) \n",
    "            raise\n",
    "       \n",
    "        \n",
    "    def update_data(self):\n",
    "        try:\n",
    "            \n",
    "            df2 = self.df2\n",
    "            df = self.df\n",
    "\n",
    "            df['origin_coord']= df2[['origin_coord']]\n",
    "            df['destination_coord']= df2[['destination_coord']]\n",
    "            df['date'] = pd.to_datetime(df['datetime']).dt.date\n",
    "\n",
    "            df['day'] = df['date'].apply(lambda x : x.day)\n",
    "            df['Hour'] = pd.to_datetime(df['datetime']).dt.hour\n",
    "            df['week'] = df['day'].apply(lambda x: (x-1)//7+1) \n",
    "            df2 = df.groupby(['region','origin_coord','destination_coord','datetime'])['region'].agg(['count'], ascending=True).\\\n",
    "                rename(columns={'count':'Total'}).reset_index()\n",
    "            df2 = df.groupby(['region'])['week'].agg(['mean'], ascending=True).\\\n",
    "                rename(columns={'mean':'weekly_avg'}).reset_index()\n",
    "            self.df2 = df2\n",
    "\n",
    "            df3 = pd.merge(left=df,right=df2,how=\"inner\", on=[\"region\"])\n",
    "\n",
    "            df4 = df3.groupby(['region','origin_coord','destination_coord','Hour','weekly_avg'])['weekly_avg'].\\\n",
    "            agg(['count'],ascending=True).rename(columns={'count':'Total'}).reset_index()\n",
    "            df4 = df4.drop(['Total'], axis=1)\n",
    "            self.df = df4\n",
    "            return df4\n",
    "        except (NameError,TypeError,UnboundLocalError,ValueError) as error:\n",
    "            print('Declare la variable correcta:',error) \n",
    "            raise\n",
    "    \n",
    "    \n",
    "    def import_data(self):\n",
    "        try:\n",
    "            \n",
    "            #se carga el df final y la conexion a la bd configurada en gcloud\n",
    "            df = self.df\n",
    "            conn_string = 'postgresql://test:test@34.72.31.189:5432/test'\n",
    "            engine = create_engine(conn_string, echo=True)\n",
    "            engine.connect()\n",
    "\n",
    "            #se crea la tabla\n",
    "            meta = MetaData()\n",
    "            trips_data = Table(\n",
    "             'trips_data', meta, \n",
    "               Column('region', String(60)), \n",
    "               Column('origin_coord', Float), \n",
    "               Column('destination_coord', Float),\n",
    "               Column('Hour', Integer), \n",
    "               Column('weekly_avg', Float),\n",
    "              \n",
    "            )\n",
    "            meta.create_all(engine)\n",
    "\n",
    "            #se insertan los datos en la tabla creada\n",
    "            df.to_sql(name ='trips_data', con=engine, index=False, chunksize=500,if_exists='replace')\n",
    "\n",
    "            #twilio enviroment token and sid\n",
    "            account_sid = os.environ['TWILIO_ACCOUNT_SID']\n",
    "            auth_token = os.environ['TWILIO_AUTH_TOKEN']\n",
    "            client = Client(account_sid,auth_token)\n",
    "            from_whatsapp_number='whatsapp:+14155238886'\n",
    "            to_whatsapp_number='whatsapp:+573013919941'\n",
    "            client.messages.create(body='Data Inserted',from_=from_whatsapp_number,to=to_whatsapp_number)\n",
    "        except (NameError,TypeError,UnboundLocalError,ValueError,TwilioRestException,AttributeError,OperationalError) as error:\n",
    "            account_sid = os.environ['TWILIO_ACCOUNT_SID']\n",
    "            auth_token = os.environ['TWILIO_AUTH_TOKEN']\n",
    "            client = Client(account_sid,auth_token)\n",
    "            from_whatsapp_number='whatsapp:+14155238886'\n",
    "            to_whatsapp_number='whatsapp:+573013919941'\n",
    "            client.messages.create(body='Data Not Inserted',from_=from_whatsapp_number,to=to_whatsapp_number)\n",
    "            raise\n",
    "               \n",
    "\n",
    "            \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "   \n",
    "       \n",
    "       \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a53bd3a-400d-4d75-b6d2-98d244fe7b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = ingest_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04737791-d03a-4c76-9001-6fbb346d8f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>origin_coord</th>\n",
       "      <th>destination_coord</th>\n",
       "      <th>datetime</th>\n",
       "      <th>datasource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prague</td>\n",
       "      <td>POINT (14.4973794438195 50.00136875782316)</td>\n",
       "      <td>POINT (14.43109483523328 50.04052930943246)</td>\n",
       "      <td>2018-05-28 09:03:40</td>\n",
       "      <td>funny_car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turin</td>\n",
       "      <td>POINT (7.672837913286881 44.9957109242058)</td>\n",
       "      <td>POINT (7.720368637535126 45.06782385393849)</td>\n",
       "      <td>2018-05-21 02:54:04</td>\n",
       "      <td>baba_car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prague</td>\n",
       "      <td>POINT (14.32427345662177 50.00002074358429)</td>\n",
       "      <td>POINT (14.47767895969969 50.09339790740321)</td>\n",
       "      <td>2018-05-13 08:52:25</td>\n",
       "      <td>cheap_mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turin</td>\n",
       "      <td>POINT (7.541509189114433 45.09160503827746)</td>\n",
       "      <td>POINT (7.74528653441973 45.02628598341506)</td>\n",
       "      <td>2018-05-06 09:49:16</td>\n",
       "      <td>bad_diesel_vehicles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turin</td>\n",
       "      <td>POINT (7.614078119815749 45.13433106465422)</td>\n",
       "      <td>POINT (7.527497142312585 45.03335051325654)</td>\n",
       "      <td>2018-05-23 12:45:54</td>\n",
       "      <td>pt_search_app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Prague</td>\n",
       "      <td>POINT (14.33562319852013 50.05977285737693)</td>\n",
       "      <td>POINT (14.45302412886982 50.06961029075634)</td>\n",
       "      <td>2018-05-03 18:56:45</td>\n",
       "      <td>cheap_mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Hamburg</td>\n",
       "      <td>POINT (9.996714798980491 53.52203690589671)</td>\n",
       "      <td>POINT (10.17431393081631 53.51796499041119)</td>\n",
       "      <td>2018-05-23 12:43:17</td>\n",
       "      <td>baba_car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Prague</td>\n",
       "      <td>POINT (14.40975521275597 50.037791514028)</td>\n",
       "      <td>POINT (14.59895464921585 50.05472087955579)</td>\n",
       "      <td>2018-05-12 08:13:09</td>\n",
       "      <td>cheap_mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Hamburg</td>\n",
       "      <td>POINT (10.08338857045871 53.59661344302611)</td>\n",
       "      <td>POINT (10.17914017806172 53.60909301795856)</td>\n",
       "      <td>2018-05-22 10:39:49</td>\n",
       "      <td>baba_car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Prague</td>\n",
       "      <td>POINT (14.61738744026195 50.03346482370401)</td>\n",
       "      <td>POINT (14.31199296863995 50.09604608872181)</td>\n",
       "      <td>2018-05-15 22:10:03</td>\n",
       "      <td>baba_car</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     region                                 origin_coord  \\\n",
       "0    Prague   POINT (14.4973794438195 50.00136875782316)   \n",
       "1     Turin   POINT (7.672837913286881 44.9957109242058)   \n",
       "2    Prague  POINT (14.32427345662177 50.00002074358429)   \n",
       "3     Turin  POINT (7.541509189114433 45.09160503827746)   \n",
       "4     Turin  POINT (7.614078119815749 45.13433106465422)   \n",
       "..      ...                                          ...   \n",
       "95   Prague  POINT (14.33562319852013 50.05977285737693)   \n",
       "96  Hamburg  POINT (9.996714798980491 53.52203690589671)   \n",
       "97   Prague    POINT (14.40975521275597 50.037791514028)   \n",
       "98  Hamburg  POINT (10.08338857045871 53.59661344302611)   \n",
       "99   Prague  POINT (14.61738744026195 50.03346482370401)   \n",
       "\n",
       "                              destination_coord             datetime  \\\n",
       "0   POINT (14.43109483523328 50.04052930943246)  2018-05-28 09:03:40   \n",
       "1   POINT (7.720368637535126 45.06782385393849)  2018-05-21 02:54:04   \n",
       "2   POINT (14.47767895969969 50.09339790740321)  2018-05-13 08:52:25   \n",
       "3    POINT (7.74528653441973 45.02628598341506)  2018-05-06 09:49:16   \n",
       "4   POINT (7.527497142312585 45.03335051325654)  2018-05-23 12:45:54   \n",
       "..                                          ...                  ...   \n",
       "95  POINT (14.45302412886982 50.06961029075634)  2018-05-03 18:56:45   \n",
       "96  POINT (10.17431393081631 53.51796499041119)  2018-05-23 12:43:17   \n",
       "97  POINT (14.59895464921585 50.05472087955579)  2018-05-12 08:13:09   \n",
       "98  POINT (10.17914017806172 53.60909301795856)  2018-05-22 10:39:49   \n",
       "99  POINT (14.31199296863995 50.09604608872181)  2018-05-15 22:10:03   \n",
       "\n",
       "             datasource  \n",
       "0             funny_car  \n",
       "1              baba_car  \n",
       "2          cheap_mobile  \n",
       "3   bad_diesel_vehicles  \n",
       "4         pt_search_app  \n",
       "..                  ...  \n",
       "95         cheap_mobile  \n",
       "96             baba_car  \n",
       "97         cheap_mobile  \n",
       "98             baba_car  \n",
       "99             baba_car  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform.process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c148d6d-c428-40a7-8438-a77d6b43c3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_coord</th>\n",
       "      <th>destination_coord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.5</td>\n",
       "      <td>14.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.7</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.3</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.5</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.6</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>14.3</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>14.4</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>10.1</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>14.6</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    origin_coord  destination_coord\n",
       "0           14.5               14.4\n",
       "1            7.7                7.7\n",
       "2           14.3               14.5\n",
       "3            7.5                7.7\n",
       "4            7.6                7.5\n",
       "..           ...                ...\n",
       "95          14.3               14.5\n",
       "96          10.0               10.2\n",
       "97          14.4               14.6\n",
       "98          10.1               10.2\n",
       "99          14.6               14.3\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform.transform_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a20889e-95e9-43f6-8ef1-fb851c4a6209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>origin_coord</th>\n",
       "      <th>destination_coord</th>\n",
       "      <th>Hour</th>\n",
       "      <th>weekly_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hamburg</td>\n",
       "      <td>9.8</td>\n",
       "      <td>9.8</td>\n",
       "      <td>9</td>\n",
       "      <td>2.821429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hamburg</td>\n",
       "      <td>9.8</td>\n",
       "      <td>10.1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.821429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hamburg</td>\n",
       "      <td>9.9</td>\n",
       "      <td>9.8</td>\n",
       "      <td>17</td>\n",
       "      <td>2.821429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hamburg</td>\n",
       "      <td>9.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.821429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hamburg</td>\n",
       "      <td>9.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2.821429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Turin</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>13</td>\n",
       "      <td>2.868421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Turin</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>15</td>\n",
       "      <td>2.868421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Turin</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>20</td>\n",
       "      <td>2.868421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Turin</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>21</td>\n",
       "      <td>2.868421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Turin</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.8</td>\n",
       "      <td>9</td>\n",
       "      <td>2.868421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     region  origin_coord  destination_coord  Hour  weekly_avg\n",
       "0   Hamburg           9.8                9.8     9    2.821429\n",
       "1   Hamburg           9.8               10.1     5    2.821429\n",
       "2   Hamburg           9.9                9.8    17    2.821429\n",
       "3   Hamburg           9.9               10.0     5    2.821429\n",
       "4   Hamburg           9.9               10.0    10    2.821429\n",
       "..      ...           ...                ...   ...         ...\n",
       "91    Turin           7.7                7.7    13    2.868421\n",
       "92    Turin           7.7                7.7    15    2.868421\n",
       "93    Turin           7.7                7.7    20    2.868421\n",
       "94    Turin           7.7                7.7    21    2.868421\n",
       "95    Turin           7.7                7.8     9    2.868421\n",
       "\n",
       "[96 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform.update_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f79f264-f410-4f79-b509-93a895e2a3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-30 20:30:11,281 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2022-01-30 20:30:11,285 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2022-01-30 20:30:11,530 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2022-01-30 20:30:11,531 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2022-01-30 20:30:11,778 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2022-01-30 20:30:11,779 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2022-01-30 20:30:12,024 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-01-30 20:30:12,026 INFO sqlalchemy.engine.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2022-01-30 20:30:12,027 INFO sqlalchemy.engine.Engine [generated in 0.00140s] {'name': 'trips_data'}\n",
      "2022-01-30 20:30:12,274 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2022-01-30 20:30:12,400 INFO sqlalchemy.engine.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2022-01-30 20:30:12,401 INFO sqlalchemy.engine.Engine [cached since 0.3749s ago] {'name': 'trips_data'}\n",
      "2022-01-30 20:30:12,772 INFO sqlalchemy.engine.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2022-01-30 20:30:12,773 INFO sqlalchemy.engine.Engine [cached since 0.7467s ago] {'name': 'trips_data'}\n",
      "2022-01-30 20:30:13,148 INFO sqlalchemy.engine.Engine SELECT c.relname FROM pg_class c JOIN pg_namespace n ON n.oid = c.relnamespace WHERE n.nspname = %(schema)s AND c.relkind in ('r', 'p')\n",
      "2022-01-30 20:30:13,149 INFO sqlalchemy.engine.Engine [generated in 0.00096s] {'schema': 'public'}\n",
      "2022-01-30 20:30:13,409 INFO sqlalchemy.engine.Engine \n",
      "            SELECT c.oid\n",
      "            FROM pg_catalog.pg_class c\n",
      "            LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace\n",
      "            WHERE (pg_catalog.pg_table_is_visible(c.oid))\n",
      "            AND c.relname = %(table_name)s AND c.relkind in\n",
      "            ('r', 'v', 'm', 'f', 'p')\n",
      "        \n",
      "2022-01-30 20:30:13,410 INFO sqlalchemy.engine.Engine [generated in 0.00102s] {'table_name': 'trips_data'}\n",
      "2022-01-30 20:30:13,540 INFO sqlalchemy.engine.Engine \n",
      "            SELECT a.attname,\n",
      "              pg_catalog.format_type(a.atttypid, a.atttypmod),\n",
      "              (\n",
      "                SELECT pg_catalog.pg_get_expr(d.adbin, d.adrelid)\n",
      "                FROM pg_catalog.pg_attrdef d\n",
      "                WHERE d.adrelid = a.attrelid AND d.adnum = a.attnum\n",
      "                AND a.atthasdef\n",
      "              ) AS DEFAULT,\n",
      "              a.attnotnull,\n",
      "              a.attrelid as table_oid,\n",
      "              pgd.description as comment,\n",
      "              a.attgenerated as generated,\n",
      "                              (SELECT json_build_object(\n",
      "                    'always', a.attidentity = 'a',\n",
      "                    'start', s.seqstart,\n",
      "                    'increment', s.seqincrement,\n",
      "                    'minvalue', s.seqmin,\n",
      "                    'maxvalue', s.seqmax,\n",
      "                    'cache', s.seqcache,\n",
      "                    'cycle', s.seqcycle)\n",
      "                FROM pg_catalog.pg_sequence s\n",
      "                JOIN pg_catalog.pg_class c on s.seqrelid = c.\"oid\"\n",
      "                WHERE c.relkind = 'S'\n",
      "                AND a.attidentity != ''\n",
      "                AND s.seqrelid = pg_catalog.pg_get_serial_sequence(\n",
      "                    a.attrelid::regclass::text, a.attname\n",
      "                )::regclass::oid\n",
      "                ) as identity_options                \n",
      "            FROM pg_catalog.pg_attribute a\n",
      "            LEFT JOIN pg_catalog.pg_description pgd ON (\n",
      "                pgd.objoid = a.attrelid AND pgd.objsubid = a.attnum)\n",
      "            WHERE a.attrelid = %(table_oid)s\n",
      "            AND a.attnum > 0 AND NOT a.attisdropped\n",
      "            ORDER BY a.attnum\n",
      "        \n",
      "2022-01-30 20:30:13,541 INFO sqlalchemy.engine.Engine [generated in 0.00100s] {'table_oid': 17073}\n",
      "2022-01-30 20:30:13,676 INFO sqlalchemy.engine.Engine \n",
      "            SELECT t.typname as \"name\",\n",
      "               pg_catalog.format_type(t.typbasetype, t.typtypmod) as \"attype\",\n",
      "               not t.typnotnull as \"nullable\",\n",
      "               t.typdefault as \"default\",\n",
      "               pg_catalog.pg_type_is_visible(t.oid) as \"visible\",\n",
      "               n.nspname as \"schema\"\n",
      "            FROM pg_catalog.pg_type t\n",
      "               LEFT JOIN pg_catalog.pg_namespace n ON n.oid = t.typnamespace\n",
      "            WHERE t.typtype = 'd'\n",
      "        \n",
      "2022-01-30 20:30:13,678 INFO sqlalchemy.engine.Engine [generated in 0.00111s] {}\n",
      "2022-01-30 20:30:13,811 INFO sqlalchemy.engine.Engine \n",
      "            SELECT t.typname as \"name\",\n",
      "               -- no enum defaults in 8.4 at least\n",
      "               -- t.typdefault as \"default\",\n",
      "               pg_catalog.pg_type_is_visible(t.oid) as \"visible\",\n",
      "               n.nspname as \"schema\",\n",
      "               e.enumlabel as \"label\"\n",
      "            FROM pg_catalog.pg_type t\n",
      "                 LEFT JOIN pg_catalog.pg_namespace n ON n.oid = t.typnamespace\n",
      "                 LEFT JOIN pg_catalog.pg_enum e ON t.oid = e.enumtypid\n",
      "            WHERE t.typtype = 'e'\n",
      "        ORDER BY \"schema\", \"name\", e.oid\n",
      "2022-01-30 20:30:13,812 INFO sqlalchemy.engine.Engine [generated in 0.00100s] {}\n",
      "2022-01-30 20:30:13,945 INFO sqlalchemy.engine.Engine \n",
      "                SELECT a.attname\n",
      "                FROM pg_attribute a JOIN (\n",
      "                    SELECT unnest(ix.indkey) attnum,\n",
      "                           generate_subscripts(ix.indkey, 1) ord\n",
      "                    FROM pg_index ix\n",
      "                    WHERE ix.indrelid = %(table_oid)s AND ix.indisprimary\n",
      "                    ) k ON a.attnum=k.attnum\n",
      "                WHERE a.attrelid = %(table_oid)s\n",
      "                ORDER BY k.ord\n",
      "            \n",
      "2022-01-30 20:30:13,946 INFO sqlalchemy.engine.Engine [generated in 0.00108s] {'table_oid': 17073}\n",
      "2022-01-30 20:30:14,079 INFO sqlalchemy.engine.Engine \n",
      "        SELECT conname\n",
      "           FROM  pg_catalog.pg_constraint r\n",
      "           WHERE r.conrelid = %(table_oid)s AND r.contype = 'p'\n",
      "           ORDER BY 1\n",
      "        \n",
      "2022-01-30 20:30:14,080 INFO sqlalchemy.engine.Engine [generated in 0.00088s] {'table_oid': 17073}\n",
      "2022-01-30 20:30:14,216 INFO sqlalchemy.engine.Engine \n",
      "          SELECT r.conname,\n",
      "                pg_catalog.pg_get_constraintdef(r.oid, true) as condef,\n",
      "                n.nspname as conschema\n",
      "          FROM  pg_catalog.pg_constraint r,\n",
      "                pg_namespace n,\n",
      "                pg_class c\n",
      "\n",
      "          WHERE r.conrelid = %(table)s AND\n",
      "                r.contype = 'f' AND\n",
      "                c.oid = confrelid AND\n",
      "                n.oid = c.relnamespace\n",
      "          ORDER BY 1\n",
      "        \n",
      "2022-01-30 20:30:14,217 INFO sqlalchemy.engine.Engine [generated in 0.00119s] {'table': 17073}\n",
      "2022-01-30 20:30:14,354 INFO sqlalchemy.engine.Engine \n",
      "              SELECT\n",
      "                  i.relname as relname,\n",
      "                  ix.indisunique, ix.indexprs,\n",
      "                  a.attname, a.attnum, c.conrelid, ix.indkey::varchar,\n",
      "                  ix.indoption::varchar, i.reloptions, am.amname,\n",
      "                  pg_get_expr(ix.indpred, ix.indrelid),\n",
      "                  ix.indnkeyatts as indnkeyatts\n",
      "              FROM\n",
      "                  pg_class t\n",
      "                        join pg_index ix on t.oid = ix.indrelid\n",
      "                        join pg_class i on i.oid = ix.indexrelid\n",
      "                        left outer join\n",
      "                            pg_attribute a\n",
      "                            on t.oid = a.attrelid and a.attnum = ANY(ix.indkey)\n",
      "                        left outer join\n",
      "                            pg_constraint c\n",
      "                            on (ix.indrelid = c.conrelid and\n",
      "                                ix.indexrelid = c.conindid and\n",
      "                                c.contype in ('p', 'u', 'x'))\n",
      "                        left outer join\n",
      "                            pg_am am\n",
      "                            on i.relam = am.oid\n",
      "              WHERE\n",
      "                  t.relkind IN ('r', 'v', 'f', 'm', 'p')\n",
      "                  and t.oid = %(table_oid)s\n",
      "                  and ix.indisprimary = 'f'\n",
      "              ORDER BY\n",
      "                  t.relname,\n",
      "                  i.relname\n",
      "            \n",
      "2022-01-30 20:30:14,355 INFO sqlalchemy.engine.Engine [generated in 0.00085s] {'table_oid': 17073}\n",
      "2022-01-30 20:30:14,491 INFO sqlalchemy.engine.Engine \n",
      "            SELECT\n",
      "                cons.conname as name,\n",
      "                cons.conkey as key,\n",
      "                a.attnum as col_num,\n",
      "                a.attname as col_name\n",
      "            FROM\n",
      "                pg_catalog.pg_constraint cons\n",
      "                join pg_attribute a\n",
      "                  on cons.conrelid = a.attrelid AND\n",
      "                    a.attnum = ANY(cons.conkey)\n",
      "            WHERE\n",
      "                cons.conrelid = %(table_oid)s AND\n",
      "                cons.contype = 'u'\n",
      "        \n",
      "2022-01-30 20:30:14,492 INFO sqlalchemy.engine.Engine [generated in 0.00111s] {'table_oid': 17073}\n",
      "2022-01-30 20:30:14,627 INFO sqlalchemy.engine.Engine \n",
      "            SELECT\n",
      "                cons.conname as name,\n",
      "                pg_get_constraintdef(cons.oid) as src\n",
      "            FROM\n",
      "                pg_catalog.pg_constraint cons\n",
      "            WHERE\n",
      "                cons.conrelid = %(table_oid)s AND\n",
      "                cons.contype = 'c'\n",
      "        \n",
      "2022-01-30 20:30:14,628 INFO sqlalchemy.engine.Engine [generated in 0.00151s] {'table_oid': 17073}\n",
      "2022-01-30 20:30:14,769 INFO sqlalchemy.engine.Engine \n",
      "            SELECT\n",
      "                pgd.description as table_comment\n",
      "            FROM\n",
      "                pg_catalog.pg_description pgd\n",
      "            WHERE\n",
      "                pgd.objsubid = 0 AND\n",
      "                pgd.objoid = %(table_oid)s\n",
      "        \n",
      "2022-01-30 20:30:14,770 INFO sqlalchemy.engine.Engine [generated in 0.00121s] {'table_oid': 17073}\n",
      "2022-01-30 20:30:15,012 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-01-30 20:30:15,014 INFO sqlalchemy.engine.Engine \n",
      "DROP TABLE trips_data\n",
      "2022-01-30 20:30:15,015 INFO sqlalchemy.engine.Engine [no key 0.00117s] {}\n",
      "2022-01-30 20:30:15,263 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2022-01-30 20:30:15,404 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-01-30 20:30:15,405 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE trips_data (\n",
      "\tregion TEXT, \n",
      "\torigin_coord FLOAT(53), \n",
      "\tdestination_coord FLOAT(53), \n",
      "\t\"Hour\" BIGINT, \n",
      "\tweekly_avg FLOAT(53)\n",
      ")\n",
      "\n",
      "\n",
      "2022-01-30 20:30:15,406 INFO sqlalchemy.engine.Engine [no key 0.00095s] {}\n",
      "2022-01-30 20:30:15,658 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2022-01-30 20:30:15,782 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-01-30 20:30:15,786 INFO sqlalchemy.engine.Engine INSERT INTO trips_data (region, origin_coord, destination_coord, \"Hour\", weekly_avg) VALUES (%(region)s, %(origin_coord)s, %(destination_coord)s, %(Hour)s, %(weekly_avg)s)\n",
      "2022-01-30 20:30:15,787 INFO sqlalchemy.engine.Engine [generated in 0.00271s] ({'region': 'Hamburg', 'origin_coord': 9.8, 'destination_coord': 9.8, 'Hour': 9, 'weekly_avg': 2.8214285714285716}, {'region': 'Hamburg', 'origin_coord': 9.8, 'destination_coord': 10.1, 'Hour': 5, 'weekly_avg': 2.8214285714285716}, {'region': 'Hamburg', 'origin_coord': 9.9, 'destination_coord': 9.8, 'Hour': 17, 'weekly_avg': 2.8214285714285716}, {'region': 'Hamburg', 'origin_coord': 9.9, 'destination_coord': 10.0, 'Hour': 5, 'weekly_avg': 2.8214285714285716}, {'region': 'Hamburg', 'origin_coord': 9.9, 'destination_coord': 10.0, 'Hour': 10, 'weekly_avg': 2.8214285714285716}, {'region': 'Hamburg', 'origin_coord': 9.9, 'destination_coord': 10.0, 'Hour': 13, 'weekly_avg': 2.8214285714285716}, {'region': 'Hamburg', 'origin_coord': 9.9, 'destination_coord': 10.2, 'Hour': 11, 'weekly_avg': 2.8214285714285716}, {'region': 'Hamburg', 'origin_coord': 10.0, 'destination_coord': 9.8, 'Hour': 1, 'weekly_avg': 2.8214285714285716}  ... displaying 10 of 96 total bound parameter sets ...  {'region': 'Turin', 'origin_coord': 7.7, 'destination_coord': 7.7, 'Hour': 21, 'weekly_avg': 2.8684210526315788}, {'region': 'Turin', 'origin_coord': 7.7, 'destination_coord': 7.8, 'Hour': 9, 'weekly_avg': 2.8684210526315788})\n",
      "2022-01-30 20:30:16,052 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "transform.import_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fc0295-5f1c-400f-b185-b6e1435b5d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b873a7-8f2f-4268-92bb-1bbb2bfbfd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea247d-d450-4c08-b51c-1f6e662147dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f81a6ad-79cf-4fa8-a45e-4a31bdd6bf3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05e07d6-a40a-4a10-b96b-d6e7acd824cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d226f30-1a98-4255-85c9-1616aa499376",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
